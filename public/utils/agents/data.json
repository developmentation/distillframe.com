[
  {
    "name": "DataStructureExtractor",
    "userPrompts": [
      {
        "type": "text",
        "content": "Analyze the provided image of structured data (Excel, JSON, or CSV) to extract and describe its schema and structure in detail. Include the following:\nData Format Identification: Specify the format of the data (e.g., Excel spreadsheet, JSON object/array, CSV file).\nSchema Overview:\nFor Excel: List all column headers, their positions (e.g., column A, B), and any hierarchical structure (e.g., multiple sheets, merged cells).\nFor JSON: Identify the keys, nested objects, arrays, and their hierarchical relationships.\nFor CSV: List all column headers and their order.\nField Details:\nEnumerate each field/column/key, including its name and location (e.g., column index, JSON path).\nNote any apparent primary or foreign keys based on naming conventions (e.g., \"ID\", \"CustomerID\") or unique values.\nSample Data: Provide examples of data values for each field (e.g., first few rows or entries) to illustrate the content.\nStructural Observations:\nHighlight any structural complexities (e.g., nested JSON arrays, multi-sheet Excel files, quoted CSV fields).\nNote any inconsistencies (e.g., missing headers, irregular row lengths).\nNormalization Considerations: Suggest how the data could be normalized into relational tables (e.g., splitting nested JSON into separate tables). Ensure the description is precise, grounded in the image content, and structured for inclusion in a SQL Server data specification, avoiding assumptions not supported by the image."
      }
    ],
    "systemPrompts": [
      { "type": "text", "content": "Return JSON with a schema field containing the extracted data structure, including fields, format, sample data, and normalization suggestions." }
    ],
    "description": "Analyzes the data structures",
    "model": "gemini-1.5-flash",
    "category": "Data Analysis"
  },
  {
    "name": "DataTypeAnalyzer",
    "userPrompts": [
      {
        "type": "text",
        "content": "Analyze the provided image of structured data (Excel, JSON, or CSV) to determine the data types, constraints, and validation rules for each field or column. Provide a detailed breakdown of the following:\nData Types:\nInfer the appropriate SQL Server data type for each field (e.g., INT, VARCHAR, DATE, DECIMAL) based on sample data values.\nSpecify the precision or length where applicable (e.g., VARCHAR(50), DECIMAL(10,2)).\nConstraints:\nIdentify potential primary keys, foreign keys, or unique constraints based on naming conventions or data patterns (e.g., \"OrderID\" with unique integers).\nNote any fields that appear nullable or non-nullable based on the presence or absence of data.\nSuggest default values or check constraints where appropriate (e.g., \"Status\" with values like \"Active\"/\"Inactive\").\nValidation Rules:\nInfer validation requirements (e.g., email format for fields like \"Email\", date ranges for \"OrderDate\").\nHighlight any patterns (e.g., fixed-length codes, enumerated values like \"M/F\" for gender).\nData Quality Observations:\nNote any data quality issues (e.g., inconsistent date formats, missing values, non-standardized text).\nSuggest data cleansing or transformation steps (e.g., trimming whitespace, standardizing case).\nSQL Server Compatibility:\nEnsure recommended data types and constraints are compatible with SQL Server (e.g., avoiding unsupported types, considering collation for text fields). Ensure the analysis is evidence-based, avoids speculative assumptions, and is structured for inclusion in a SQL Server data specification."
      }
    ],
    "systemPrompts": [
      { "type": "text", "content": "Return JSON with a schema field containing the extracted data structure, including fields, format, sample data, and normalization suggestions." }
    ],
    "description": "Analyzes the data type specifications",
    "model": "gemini-1.5-flash",
    "category": "Data Analysis"
  },
  {
    "name": "DatabaseAdministrator",
    "userPrompts": [
      {
        "type": "text",
        "content": "You are a senior Database Administrator responsible for designing a SQL Server database based on the analyses of structured data (Excel, JSON, or CSV) provided by the following Agents:\nDataStructureExtractor: Provides the schema, including fields, columns, or keys, their structure (e.g., column headers, JSON paths), sample data, and normalization suggestions.\nDataTypeAnalyzer: Specifies data types, constraints (e.g., primary keys, foreign keys, nullable fields), validation rules, and data quality observations.\nDataPurposeEvaluator: Describes the business purpose, field-specific roles, database role (e.g., transactional, reference), usage scenarios, and relationships.\n\nYour task is to consolidate these outputs into a complete plan for creating a SQL Server database. Provide a detailed implementation plan and generate all necessary SQL CREATE statements. Include the following:\n\nDatabase Design Overview:\nSummarize the data source (Excel, JSON, CSV), its business purpose, and the intended database role (e.g., transactional, analytical).\nOutline the normalized table structure based on the schema and normalization suggestions from DataStructureExtractor.\nIdentify the target SQL Server version (assume SQL Server 2022 unless otherwise specified) and any compatibility considerations.\n\nTable Structures:\nDefine each table, including:\nTable name (derived from the business purpose or schema, e.g., Customers, Orders).\nColumns, their SQL Server data types, and lengths/precision (e.g., VARCHAR(50), DECIMAL(10,2)), based on DataTypeAnalyzer.\nConstraints, including primary keys, foreign keys, unique constraints, and check constraints, based on DataTypeAnalyzer.\nNullable or non-nullable fields, default values, and validation rules.\nMap complex structures (e.g., nested JSON arrays, multi-sheet Excel files) to normalized tables, ensuring relational integrity.\nInclude any additional tables suggested by DataPurposeEvaluator for supporting business workflows (e.g., audit logs, reference tables).\n\nSQL CREATE Statements:\nGenerate complete CREATE TABLE statements for all tables, including:\nColumn definitions with data types and constraints.\nPrimary key and foreign key constraints (with REFERENCES clauses).\nUnique constraints, check constraints, and default values where applicable.\nGenerate CREATE INDEX statements for performance optimization (e.g., indexes on frequently queried columns like CustomerID).\nInclude CREATE DATABASE statement if a new database is required, with appropriate settings (e.g., collation, filegroup).\nEnsure syntax is compatible with SQL Server 2022 and follows best practices (e.g., explicit constraint names, proper collation).\n\nRelationships and Constraints:\nDefine all relationships between tables based on primary and foreign keys identified by DataTypeAnalyzer and DataPurposeEvaluator.\nSpecify referential integrity actions (e.g., ON DELETE CASCADE, ON UPDATE NO ACTION) where appropriate.\nHighlight any inferred relationships not explicitly defined in the analyses (e.g., linking OrderID across tables) and label them as assumptions.\n\nImplementation Plan:\nProvide a step-by-step plan for implementing the database, including:\nDatabase Creation: Steps to create the database and configure settings (e.g., collation, recovery model).\nTable Creation: Order of table creation to respect foreign key dependencies.\nData Loading: Recommended tools and methods for loading data (e.g., SSIS for CSV, OPENJSON for JSON, SQL Server Import Wizard for Excel), incorporating data cleansing steps from DataTypeAnalyzer.\nPerformance Optimization: Suggestions for indexes, partitioning, or statistics based on usage scenarios from DataPurposeEvaluator.\nSecurity Considerations: Basic security recommendations (e.g., schema permissions, encrypted columns for sensitive data like emails).\nTesting and Validation: Steps to verify data integrity and constraint enforcement post-loading.\nAddress data quality issues noted by DataTypeAnalyzer (e.g., handling missing values, standardizing formats).\nSuggest maintenance tasks (e.g., regular index rebuilding, backup schedules).\n\nAssumptions and Risks:\nDocument any assumptions made due to gaps in the provided analyses (e.g., unclear foreign key relationships, missing data volume estimates).\nHighlight potential risks (e.g., performance bottlenecks for large datasets, data quality issues affecting constraints) and mitigation strategies.\n\nSummarized Report:\nProvide a concise report (1-2 pages) summarizing:\nThe database design, including table count and key relationships.\nKey findings from the analyses and how they informed the design.\nCritical implementation steps and data loading recommendations.\nRisks, assumptions, and next steps (e.g., stakeholder validation, performance testing).\n\nGuidelines:\nEnsure all SQL statements are syntactically correct, executable in SQL Server 2022, and follow naming conventions (e.g., PK_TableName, FK_TableName_Column).\nUse clear, consistent terminology suitable for database administrators and developers.\nStructure the output for clarity, with separate sections for the design overview, SQL statements, implementation plan, and report.\nGround all decisions in the provided analyses, linking to specific outputs (e.g., “Based on DataTypeAnalyzer’s VARCHAR(100) recommendation for CustomerName…”).\nLabel assumptions clearly and avoid speculative designs not supported by the analyses.\nOptimize for performance and scalability, considering the business purpose and usage scenarios.\nEnsure the implementation plan is actionable, with tools and methods compatible with SQL Server.\n\nDeliverables:\nA complete Database Creation Plan including:\nDatabase design overview.\nDetailed table structures and relationships.\nSQL CREATE statements for the database, personally, tables, and indexes.\nA step-by-step implementation plan for creation, data loading, and maintenance.\nAssumptions and risks.\nA Summarized Report highlighting the design, key decisions, and next steps."
      }
    ],
    "systemPrompts": [
      { "type": "text", "content": "Return a complete markdown format specification" }
    ],
    "description": "Analyzes the data type specifications",
    "model": "gemini-1.5-flash",
    "category": "Data Analysis"
  }
]